# -*- coding: utf-8 -*-
"""Seamlessv7-5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1noh5DZ5cFs2VcWIUkJl4M1fa8gOE5HfX
"""

#run before running the server

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install fastapi uvicorn pyngrok torchaudio google-genai

from google import genai
from google.genai import types
import asyncio
import numpy as np
import soundfile as sf
import io
import torchaudio
import torch
import os

def build_configs():
    # Configs
    configs = {}

    configs["EN_F"] = types.LiveConnectConfig(
        system_instruction="You are a translator. When I send you text, translate it to English and ONLY respond with the English translation. Do not have a conversation, do not ask questions, do not explain - just translate to English using English alphabet only. Speak the translation clearly and a bit fast.",
        response_modalities=["AUDIO"],
        speech_config=types.SpeechConfig(
            voice_config=types.VoiceConfig(
                prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Achernar")
            )
        ),
        output_audio_transcription=types.AudioTranscriptionConfig(),
    )

    configs["EN_M"] = types.LiveConnectConfig(
        system_instruction="You are a translator. When I send you text, translate it to English and ONLY respond with the English translation. Do not have a conversation, do not ask questions, do not explain - just translate to English using English alphabet only. Speak the translation clearly and a bit fast.",
        response_modalities=["AUDIO"],
        speech_config=types.SpeechConfig(
            voice_config=types.VoiceConfig(
                prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Algenib")
            )
        ),
        output_audio_transcription=types.AudioTranscriptionConfig(),
    )

    configs["FA_F"] = types.LiveConnectConfig(
        system_instruction="شما یک مترجم هستید. وقتی متنی برایتان ارسال می‌کنم، آن را به فارسی ترجمه کنید و فقط با ترجمه فارسی پاسخ دهید. گفتگو نکنید، سوال نپرسید، توضیح ندهید - فقط به فارسی ترجمه کنید و فقط از الفبای فارسی استفاده کنید. از فینگلیش یا حروف لاتین استفاده نکنید. ترجمه را واضح و کمی سریع بگویید.",
        response_modalities=["AUDIO"],
        speech_config=types.SpeechConfig(
            voice_config=types.VoiceConfig(
                prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Achernar")
            )
        ),
        output_audio_transcription=types.AudioTranscriptionConfig(),
    )

    configs["FA_M"] = types.LiveConnectConfig(
        system_instruction="شما یک مترجم هستید. وقتی متنی برایتان ارسال می‌کنم، آن را به فارسی ترجمه کنید و فقط با ترجمه فارسی پاسخ دهید. گفتگو نکنید، سوال نپرسید، توضیح ندهید - فقط به فارسی ترجمه کنید و فقط از الفبای فارسی استفاده کنید. از فینگلیش یا حروف لاتین استفاده نکنید. ترجمه را واضح و کمی سریع بگویید.",
        response_modalities=["AUDIO"],
        speech_config=types.SpeechConfig(
            voice_config=types.VoiceConfig(
                prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Algenib")
            )
        ),
        output_audio_transcription=types.AudioTranscriptionConfig(),
    )

    configs["AR_F"] = types.LiveConnectConfig(
        system_instruction="أنت مترجم. عندما أرسل لك نصاً، ترجمه إلى العربية واستجب فقط بالترجمة العربية. لا تتحدث معي، لا تسأل أسئلة، لا تشرح - فقط ترجم إلى العربية باستخدام الأبجدية العربية فقط. لا تستخدم الأبجدية اللاتينية أو النص المُعرّب. انطق الترجمة بوضوح وبسرعة قليلاً.",
        response_modalities=["AUDIO"],
        speech_config=types.SpeechConfig(
            voice_config=types.VoiceConfig(
                prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Achernar")
            )
        ),
        output_audio_transcription=types.AudioTranscriptionConfig(),
    )

    configs["AR_M"] = types.LiveConnectConfig(
        system_instruction="أنت مترجم. عندما أرسل لك نصاً، ترجمه إلى العربية واستجب فقط بالترجمة العربية. لا تتحدث معي، لا تسأل أسئلة، لا تشرح - فقط ترجم إلى العربية باستخدام الأبجدية العربية فقط. لا تستخدم الأبجدية اللاتينية أو النص المُعرّب. انطق الترجمة بوضوح وبسرعة قليلاً.",
        response_modalities=["AUDIO"],
        speech_config=types.SpeechConfig(
            voice_config=types.VoiceConfig(
                prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Algenib")
            )
        ),
        output_audio_transcription=types.AudioTranscriptionConfig(),
    )

    return configs

def build_clients():
    # Clients
    clients = {}


    clients["EN_M"] = genai.Client(api_key=os.getenv('EN1'))
    clients["EN_F"] = genai.Client(api_key=os.getenv('EN2'))
    clients["AR_M"] = genai.Client(api_key=os.getenv('AR1'))
    clients["AR_F"] = genai.Client(api_key=os.getenv('AR2'))
    clients["FA_M"] = genai.Client(api_key=os.getenv('FA1'))
    clients["FA_F"] = genai.Client(api_key=os.getenv('FA2'))

    return clients

async def gemini_translate(client, model, config, text_input):
    audio_data = b''
    transcript_text = ''

    try:
        async with client.aio.live.connect(model=model, config=config) as session:
            await session.send_client_content(
                turns={"role": "user", "parts": [{"text": text_input}]},
                turn_complete=True
            )

            async for response in session.receive():
                if response.server_content.model_turn:
                    for part in response.server_content.model_turn.parts:
                        if part.inline_data and part.inline_data.mime_type.startswith("audio/"):
                            audio_data += part.inline_data.data
                if response.server_content.output_transcription:
                    transcript_text += response.server_content.output_transcription.text

            # Interpret raw PCM data
            sample_rate = 24000
            target_sample_rate = 16000
            dtype = np.int16

            print(f"Raw audio data length: {len(audio_data)} bytes")

            audio_np = np.frombuffer(audio_data, dtype=dtype)
            print(f"Audio array shape: {audio_np.shape}, min/max: {audio_np.min()}/{audio_np.max()}")

            # Convert to float32 and normalize to [-1, 1]
            audio_float = audio_np.astype(np.float32) / 32768.0
            waveform = torch.tensor(audio_float).unsqueeze(0)  # shape: [1, time]

            # Resample
            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)
            waveform = resampler(waveform)

            audio_samples = waveform.squeeze().cpu().numpy()  # shape: [time]
            print(f"Final audio shape: {audio_samples.shape}, min/max: {audio_samples.min()}/{audio_samples.max()}")

            return audio_samples, transcript_text, target_sample_rate
    except Exception as e:
        print(f"Error in gemini_translate: {e}")
        raise  # Re-raise to trigger session recreation

import torchaudio, torch

async def t2S_translate(model, text_input, tgt_lang, speaker_id):
  # Clients anf configs (should differ for each language and speaker)
  if tgt_lang == "en-US":
    if speaker_id==0:
      client = clients["EN_F"]
      conf = configs["EN_F"]
    else:
      client = clients["EN_M"]
      conf = configs["EN_M"]

  elif tgt_lang == "ar-SA":
    if speaker_id==0:
      client = clients["AR_F"]
      conf = configs["AR_F"]
    else:
      client = clients["AR_M"]
      conf = configs["AR_M"]

  elif tgt_lang == "fa-IR":
    if speaker_id==0:
      client = clients["FA_F"]
      conf = configs["FA_F"]
    else:
      client = clients["FA_M"]
      conf = configs["FA_M"]

  else:
    raise ValueError(f"Unsupported target language: {tgt_lang}")

  audio_bytes, translated_text, sample_rate = await gemini_translate(
    client=client,
    model=model,
    config=conf,
    text_input=text_input
)

  return audio_bytes, sample_rate, translated_text

# Set up Fast api
import asyncio, time, base64, io
from collections import defaultdict
from fastapi import FastAPI, WebSocket
from typing import Dict, List
from contextlib import asynccontextmanager
from starlette.websockets import WebSocketState
#from file import t2S_translate
current_recorder: WebSocket | None = None

global model
model = "gemini-2.5-flash-preview-native-audio-dialog"

PING_TIMEOUT = 40  # seconds

@asynccontextmanager
async def lifespan(app: FastAPI):
    global configs
    global clients
    configs = build_configs()
    clients = build_clients()
    print("Starting up...")
    yield
    print("Shutting down. Closing all WebSocket connections...")
    websockets = list(rooms[DEFAULT_ROOM].keys())

    for ws in websockets:
        try:
            await ws.close(code=1001)  # 1001 = Going Away
        except Exception as e:
            print(f"WebSocket Disconnected! {e} ")
        finally:
            rooms[DEFAULT_ROOM].pop(ws, None)

    print("Shutdown complete.")

app = FastAPI(lifespan=lifespan)

DEFAULT_ROOM = "default_room"
rooms: Dict[str, Dict[WebSocket, Dict]] = {
    DEFAULT_ROOM: {}
}

async def translate(src_lang, tgt_lang, text, speaker_id):
    speaker_id = int(speaker_id)
    try:
        audio, sample_rate, translated_text = await t2S_translate(model, text, tgt_lang, speaker_id)
        if len(audio) == 0:
            print("WARNING: Empty audio received!")
            return translated_text, ""

        # Debug info
        print(f"Final audio for WAV - shape: {audio.shape}, min/max: {audio.min()}/{audio.max()}")

        buffer = io.BytesIO()
        torchaudio.save(buffer, torch.from_numpy(audio).unsqueeze(0), sample_rate, format="wav")
        buffer.seek(0)
        audio_b64 = base64.b64encode(buffer.read()).decode("utf-8")

        print(f"Base64 audio length: {len(audio_b64)} chars")
        return translated_text, audio_b64

    except Exception as e:
        print(f"Error in translate function: {e}")
        return f"Translation error: {str(e)}", ""


async def group_translate(connections, src_lang: str, tgt_lang: str, text: str, speaker_id: int):
    translated_text, audio_b64 = await translate(src_lang, tgt_lang, text, speaker_id)

    for ws in connections:
        try:
            await ws.send_json({
              "type" : "translate_msg",
              "transcript": text,
              "translated_text": translated_text,
              "translated_audio_url": audio_b64,
              "src_lang": src_lang,
              "tgt_lang": tgt_lang,
            })
            print(f"WebSocket x recieved src_lang: {src_lang}, tgt_lang: {tgt_lang}")
        except Exception as e:
          print(f"Error translating for group {tgt_lang}/{speaker_id}: {e}")

async def just_send(ws: WebSocket, src_lang: str, text: str):

    try:
        await ws.send_json({
            "type" : "transcript_msg",
            "transcript": text,
            "src_lang": src_lang
        })
        print(f"WebSocket x recieved src_lang: {src_lang}")
    except Exception as e:
        print(f"Error: {e}")

async def per_record(connections, per: bool):
    for ws in connections:
        try:
            await ws.send_json({
                "type" : "per_record",
                "per_record": per,
            })
            print(f"per_record: {per}")
        except Exception as e:
            print(f"Error: {e}")

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    global current_recorder

    # Send current per_record state to the new user
    await websocket.send_json({
        "type": "per_record",
        "per_record": current_recorder is None  # True => اجازه رکورد هست
    })

    # Set default values
    user_data = {
        "lang": "en-US",
        "speaker_id": "0",
        "last_ping": time.time()
    }

    # Add user to default room
    rooms[DEFAULT_ROOM][websocket] = user_data
    last_active = time.time()

    try:
        while True:
            if websocket.client_state != WebSocketState.CONNECTED:
                break

            try:
                data = await websocket.receive_json()
                last_active = time.time()
                # global current_recorder

                if data.get("type") == "update_settings":
                    lang = data.get("lang", "en-US")
                    speaker_id = int(data.get("speaker_id", "0"))
                    rooms[DEFAULT_ROOM][websocket]["lang"] = lang
                    rooms[DEFAULT_ROOM][websocket]["speaker_id"] = speaker_id
                    await websocket.send_json({"status": "settings_updated"})
                    print(f"WebSocket {websocket} updated settings: lang={lang}, speaker_id={speaker_id}")

                elif data.get("type") == "ping":
                    await websocket.send_json({"type": "pong"})
                    user_data["last_ping"] = last_active

                elif data.get("type") == "speak":
                    src_lang = data.get("src_lang")
                    text = data.get("text")
                    speaker_id = int(data.get("speaker_id", "0"))
                    print(f"ws x , src_lang: {src_lang} *type speak")
                    if not src_lang or not text:
                        continue

                    # Group users by their language + speaker_id
                    groups = defaultdict(list)
                    for ws, info in rooms[DEFAULT_ROOM].items():
                        key = (info["lang"], info["speaker_id"])
                        groups[key].append(ws)

                    tasks = []
                    for (tgt_lang, speaker_id), connections in groups.items():
                        if src_lang == tgt_lang:
                            for ws in connections:
                                tasks.append(
                                    just_send(ws, src_lang, text)
                                    )
                        else:
                            tasks.append(
                                group_translate(connections, src_lang, tgt_lang, text, speaker_id)
                            )
                    await asyncio.gather(*tasks)
                elif data.get("type") == "status_Record":
                    if data.get("statusRecord") == True:
                        await per_record(list(rooms[DEFAULT_ROOM].keys()), False)
                        current_recorder = websocket
                    elif data.get("statusRecord") == False:
                        await per_record(list(rooms[DEFAULT_ROOM].keys()), True)
                        current_recorder = None


            except Exception as e:
                print(f"Client error: {e}")
                break

            if time.time() - last_active > PING_TIMEOUT:
                print("Client inactive, disconnecting.")
                break

    except Exception as e:
        print(f"Connection error: {e}")

    finally:
        rooms[DEFAULT_ROOM].pop(websocket, None)

        # همیشه بررسی کنیم که اگر این کاربر رکوردر بود، آن را خالی کنیم
        if current_recorder == websocket:
            await per_record(list(rooms[DEFAULT_ROOM].keys()), True)
            current_recorder = None

        # تلاش برای بستن سوکت
        try:
            await websocket.close()
        except Exception as e:
            print(f"Error closing WebSocket: {e}")

    # finally:
    #     rooms[DEFAULT_ROOM].pop(websocket, None)
    #     if websocket.client_state != WebSocketState.DISCONNECTED:
    #         if current_recorder == websocket:
    #             await per_record(list(rooms[DEFAULT_ROOM].keys()), True)
    #             current_recorder = None
    #         try:
    #             await websocket.close()
    #         except Exception as e:
    #             print(f"Error closing WebSocket: {e}")



import uvicorn

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("your_module_name:app", host="0.0.0.0", port=8000, reload=True)
