# -*- coding: utf-8 -*-
"""Seamlessv8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aCDXGHOPQvgPkz_3rKOilzRGXM7XTNIG
"""

#run before running the server

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install fastapi uvicorn pyngrok torchaudio google-genai

from google import genai
from google.colab import userdata
from google.genai import types
import asyncio
import numpy as np
import soundfile as sf
import io
import torchaudio
import torch

# SessionManager.py
class SessionManager:
    def __init__(self, model, clients, configs):
        self.model = model
        self.clients = clients
        self.configs = configs
        self.sessions: dict[str, tuple[any, any]] = {}  # key -> (session, context_manager)

    async def get_or_create(self, key: str):
        if key in self.sessions:
            session, _ = self.sessions[key]
            return session

        client = self.clients[key]
        config = self.configs[key]

        session_cm = client.aio.live.connect(model=self.model, config=config)
        session = await session_cm.__aenter__()

        self.sessions[key] = (session, session_cm)
        print(f"ðŸš€ Started session for: {key}")
        return session

    async def _cleanup_session(self, key: str):
        if key in self.sessions:
            _, session_cm = self.sessions[key]
            try:
                await session_cm.__aexit__(None, None, None)
                print(f"ðŸ§¹ Cleaned up session: {key}")
            except Exception as e:
                print(f"Error closing session {key}: {e}")
            del self.sessions[key]

    async def close_all(self):
        for key in list(self.sessions.keys()):
            await self._cleanup_session(key)

import os
clients["EN_M"] = genai.Client(api_key=os.getenv('EN1'))


def build_clients():
    # Clients
    clients = {}

    clients["EN_M"] = genai.Client(api_key=os.getenv('EN1'))
    clients["EN_F"] = genai.Client(api_key=os.getenv('EN2'))
    clients["AR_M"] = genai.Client(api_key=os.getenv('AR1'))
    clients["AR_F"] = genai.Client(api_key=os.getenv('AR2'))
    clients["FA_M"] = genai.Client(api_key=os.getenv('FA1'))
    clients["FA_F"] = genai.Client(api_key=os.getenv('FA2'))
    return clients

def build_configs():
    # Configs
    configs = {}

    configs["EN_F"] = types.LiveConnectConfig(
        system_instruction="You are a translator. When I send you text, translate it to English and ONLY respond with the English translation. Do not have a conversation, do not ask questions, do not explain - just translate to English using English alphabet only. Speak the translation clearly and a bit fast.",
        response_modalities=["AUDIO"],
        speech_config=types.SpeechConfig(
            voice_config=types.VoiceConfig(
                prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Achernar")
            )
        ),
        output_audio_transcription=types.AudioTranscriptionConfig(),
    )

    configs["EN_M"] = types.LiveConnectConfig(
        system_instruction="You are a translator. When I send you text, translate it to English and ONLY respond with the English translation. Do not have a conversation, do not ask questions, do not explain - just translate to English using English alphabet only. Speak the translation clearly and a bit fast.",
        response_modalities=["AUDIO"],
        speech_config=types.SpeechConfig(
            voice_config=types.VoiceConfig(
                prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Algenib")
            )
        ),
        output_audio_transcription=types.AudioTranscriptionConfig(),
    )

    configs["FA_F"] = types.LiveConnectConfig(
        system_instruction="Ø´Ù…Ø§ ÛŒÚ© Ù…ØªØ±Ø¬Ù… Ù‡Ø³ØªÛŒØ¯. ÙˆÙ‚ØªÛŒ Ù…ØªÙ†ÛŒ Ø¨Ø±Ø§ÛŒØªØ§Ù† Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù…ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ ØªØ±Ø¬Ù…Ù‡ Ú©Ù†ÛŒØ¯ Ùˆ ÙÙ‚Ø· Ø¨Ø§ ØªØ±Ø¬Ù…Ù‡ ÙØ§Ø±Ø³ÛŒ Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯. Ú¯ÙØªÚ¯Ùˆ Ù†Ú©Ù†ÛŒØ¯ØŒ Ø³ÙˆØ§Ù„ Ù†Ù¾Ø±Ø³ÛŒØ¯ØŒ ØªÙˆØ¶ÛŒØ­ Ù†Ø¯Ù‡ÛŒØ¯ - ÙÙ‚Ø· Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ ØªØ±Ø¬Ù…Ù‡ Ú©Ù†ÛŒØ¯ Ùˆ ÙÙ‚Ø· Ø§Ø² Ø§Ù„ÙØ¨Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯. Ø§Ø² ÙÛŒÙ†Ú¯Ù„ÛŒØ´ ÛŒØ§ Ø­Ø±ÙˆÙ Ù„Ø§ØªÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†ÛŒØ¯. ØªØ±Ø¬Ù…Ù‡ Ø±Ø§ ÙˆØ§Ø¶Ø­ Ùˆ Ú©Ù…ÛŒ Ø³Ø±ÛŒØ¹ Ø¨Ú¯ÙˆÛŒÛŒØ¯.",
        response_modalities=["AUDIO"],
        speech_config=types.SpeechConfig(
            voice_config=types.VoiceConfig(
                prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Achernar")
            )
        ),
        output_audio_transcription=types.AudioTranscriptionConfig(),
    )

    configs["FA_M"] = types.LiveConnectConfig(
        system_instruction="Ø´Ù…Ø§ ÛŒÚ© Ù…ØªØ±Ø¬Ù… Ù‡Ø³ØªÛŒØ¯. ÙˆÙ‚ØªÛŒ Ù…ØªÙ†ÛŒ Ø¨Ø±Ø§ÛŒØªØ§Ù† Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù…ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ ØªØ±Ø¬Ù…Ù‡ Ú©Ù†ÛŒØ¯ Ùˆ ÙÙ‚Ø· Ø¨Ø§ ØªØ±Ø¬Ù…Ù‡ ÙØ§Ø±Ø³ÛŒ Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯. Ú¯ÙØªÚ¯Ùˆ Ù†Ú©Ù†ÛŒØ¯ØŒ Ø³ÙˆØ§Ù„ Ù†Ù¾Ø±Ø³ÛŒØ¯ØŒ ØªÙˆØ¶ÛŒØ­ Ù†Ø¯Ù‡ÛŒØ¯ - ÙÙ‚Ø· Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ ØªØ±Ø¬Ù…Ù‡ Ú©Ù†ÛŒØ¯ Ùˆ ÙÙ‚Ø· Ø§Ø² Ø§Ù„ÙØ¨Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯. Ø§Ø² ÙÛŒÙ†Ú¯Ù„ÛŒØ´ ÛŒØ§ Ø­Ø±ÙˆÙ Ù„Ø§ØªÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†ÛŒØ¯. ØªØ±Ø¬Ù…Ù‡ Ø±Ø§ ÙˆØ§Ø¶Ø­ Ùˆ Ú©Ù…ÛŒ Ø³Ø±ÛŒØ¹ Ø¨Ú¯ÙˆÛŒÛŒØ¯.",
        response_modalities=["AUDIO"],
        speech_config=types.SpeechConfig(
            voice_config=types.VoiceConfig(
                prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Algenib")
            )
        ),
        output_audio_transcription=types.AudioTranscriptionConfig(),
    )

    configs["AR_F"] = types.LiveConnectConfig(
        system_instruction="Ø£Ù†Øª Ù…ØªØ±Ø¬Ù…. Ø¹Ù†Ø¯Ù…Ø§ Ø£Ø±Ø³Ù„ Ù„Ùƒ Ù†ØµØ§Ù‹ØŒ ØªØ±Ø¬Ù…Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ø³ØªØ¬Ø¨ ÙÙ‚Ø· Ø¨Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ù„Ø§ ØªØªØ­Ø¯Ø« Ù…Ø¹ÙŠØŒ Ù„Ø§ ØªØ³Ø£Ù„ Ø£Ø³Ø¦Ù„Ø©ØŒ Ù„Ø§ ØªØ´Ø±Ø­ - ÙÙ‚Ø· ØªØ±Ø¬Ù… Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¨Ø¬Ø¯ÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·. Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø¨Ø¬Ø¯ÙŠØ© Ø§Ù„Ù„Ø§ØªÙŠÙ†ÙŠØ© Ø£Ùˆ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ¹Ø±Ù‘Ø¨. Ø§Ù†Ø·Ù‚ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¨ÙˆØ¶ÙˆØ­ ÙˆØ¨Ø³Ø±Ø¹Ø© Ù‚Ù„ÙŠÙ„Ø§Ù‹.",
        response_modalities=["AUDIO"],
        speech_config=types.SpeechConfig(
            voice_config=types.VoiceConfig(
                prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Achernar")
            )
        ),
        output_audio_transcription=types.AudioTranscriptionConfig(),
    )

    configs["AR_M"] = types.LiveConnectConfig(
        system_instruction="Ø£Ù†Øª Ù…ØªØ±Ø¬Ù…. Ø¹Ù†Ø¯Ù…Ø§ Ø£Ø±Ø³Ù„ Ù„Ùƒ Ù†ØµØ§Ù‹ØŒ ØªØ±Ø¬Ù…Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ø³ØªØ¬Ø¨ ÙÙ‚Ø· Ø¨Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ù„Ø§ ØªØªØ­Ø¯Ø« Ù…Ø¹ÙŠØŒ Ù„Ø§ ØªØ³Ø£Ù„ Ø£Ø³Ø¦Ù„Ø©ØŒ Ù„Ø§ ØªØ´Ø±Ø­ - ÙÙ‚Ø· ØªØ±Ø¬Ù… Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¨Ø¬Ø¯ÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·. Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø¨Ø¬Ø¯ÙŠØ© Ø§Ù„Ù„Ø§ØªÙŠÙ†ÙŠØ© Ø£Ùˆ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ¹Ø±Ù‘Ø¨. Ø§Ù†Ø·Ù‚ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¨ÙˆØ¶ÙˆØ­ ÙˆØ¨Ø³Ø±Ø¹Ø© Ù‚Ù„ÙŠÙ„Ø§Ù‹.",
        response_modalities=["AUDIO"],
        speech_config=types.SpeechConfig(
            voice_config=types.VoiceConfig(
                prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Algenib")
            )
        ),
        output_audio_transcription=types.AudioTranscriptionConfig(),
    )

    return configs

async def gemini_translate(session, text_input):
    audio_data = b''
    transcript_text = ''

    try:
        await session.send_client_content(
            turns={"role": "user", "parts": [{"text": text_input}]},
            turn_complete=True
        )

        async for response in session.receive():
            if response.server_content.model_turn:
                for part in response.server_content.model_turn.parts:
                    if part.inline_data and part.inline_data.mime_type.startswith("audio/"):
                        audio_data += part.inline_data.data
            if response.server_content.output_transcription:
                transcript_text += response.server_content.output_transcription.text

        if not audio_data:
            print("WARNING: No audio data received from Gemini!")
            return np.array([]), transcript_text, 16000

        # Interpret raw PCM data
        sample_rate = 24000
        target_sample_rate = 16000
        dtype = np.int16

        print(f"Raw audio data length: {len(audio_data)} bytes")

        audio_np = np.frombuffer(audio_data, dtype=dtype)
        print(f"Audio array shape: {audio_np.shape}, min/max: {audio_np.min()}/{audio_np.max()}")

        # Convert to float32 and normalize to [-1, 1]
        audio_float = audio_np.astype(np.float32) / 32768.0
        waveform = torch.tensor(audio_float).unsqueeze(0)  # shape: [1, time]

        # Resample
        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)
        waveform = resampler(waveform)

        audio_samples = waveform.squeeze().cpu().numpy()  # shape: [time]
        print(f"Final audio shape: {audio_samples.shape}, min/max: {audio_samples.min()}/{audio_samples.max()}")

        return audio_samples, transcript_text, target_sample_rate

    except Exception as e:
        print(f"Error in gemini_translate: {e}")
        raise  # Re-raise to trigger session recreation

import torchaudio, torch
from IPython.display import Audio

async def t2S_translate(session_manager, text_input, tgt_lang, speaker_id):
    if tgt_lang == "en-US":
        key = "EN_F" if speaker_id == 0 else "EN_M"
    elif tgt_lang == "ar-SA":
        key = "AR_F" if speaker_id == 0 else "AR_M"
    elif tgt_lang == "fa-IR":
        key = "FA_F" if speaker_id == 0 else "FA_M"
    else:
        raise ValueError(f"Unsupported target language: {tgt_lang}")

    max_retries = 2
    for attempt in range(max_retries):
        try:
            session = await session_manager.get_or_create(key)

            audio_bytes, translated_text, sample_rate = await gemini_translate(session, text_input)
            return audio_bytes, sample_rate, translated_text
        except Exception as e:
            print(f"Attempt {attempt + 1} failed for {key}: {e}")
            # Force session recreation on next attempt
            await session_manager._cleanup_session(key)
            if attempt == max_retries - 1:
                raise

# Set up Fast api
import asyncio, time, base64, io
from collections import defaultdict
from fastapi import FastAPI, WebSocket
from typing import Dict, List
from contextlib import asynccontextmanager
from starlette.websockets import WebSocketState
#from file import t2S_translate
current_recorder: WebSocket | None = None

PING_TIMEOUT = 40  # seconds
model = "gemini-2.5-flash-preview-native-audio-dialog"
session_manager = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global session_manager
    print("ðŸ”„ Loading config + client keys...")
    configs = build_configs()
    clients = build_clients()
    session_manager = SessionManager(model, clients, configs)
    print("âœ… Ready for requests!")
    yield
    print("Shutting down. Closing all WebSocket connections...")
    websockets = list(rooms[DEFAULT_ROOM].keys())
    print("ðŸ”» Closing sessions...")
    await session_manager.close_all()
    print("âœ… Sessions closed!")

    for ws in websockets:
        try:
            await ws.close(code=1001)  # 1001 = Going Away
        except Exception as e:
            print(f"WebSocket Disconnected! {e} ")
        finally:
            rooms[DEFAULT_ROOM].pop(ws, None)

    print("Shutdown complete.")

app = FastAPI(lifespan=lifespan)

sessions = {}
DEFAULT_ROOM = "default_room"
rooms: Dict[str, Dict[WebSocket, Dict]] = {
    DEFAULT_ROOM: {}
}



async def translate(src_lang, tgt_lang, text, speaker_id):
    speaker_id = int(speaker_id)

    try:
        audio, sample_rate, translated_text = await t2S_translate(session_manager, text, tgt_lang, speaker_id)

        if len(audio) == 0:
            print("WARNING: Empty audio received!")
            return translated_text, ""

        # Debug info
        print(f"Final audio for WAV - shape: {audio.shape}, min/max: {audio.min()}/{audio.max()}")

        buffer = io.BytesIO()
        torchaudio.save(buffer, torch.from_numpy(audio).unsqueeze(0), sample_rate, format="wav")
        buffer.seek(0)
        audio_b64 = base64.b64encode(buffer.read()).decode("utf-8")

        print(f"Base64 audio length: {len(audio_b64)} chars")
        return translated_text, audio_b64

    except Exception as e:
        print(f"Error in translate function: {e}")
        return f"Translation error: {str(e)}", ""

async def group_translate(connections, src_lang: str, tgt_lang: str, text: str, speaker_id: int):
    translated_text, audio_b64 = await translate(src_lang, tgt_lang, text, speaker_id)

    for ws in connections:
        try:
            await ws.send_json({
              "type" : "translate_msg",
              "transcript": text,
              "translated_text": translated_text,
              "translated_audio_url": audio_b64,
              "src_lang": src_lang,
              "tgt_lang": tgt_lang,
            })
            print(f"WebSocket x recieved src_lang: {src_lang}, tgt_lang: {tgt_lang}")
        except Exception as e:
          print(f"Error translating for group {tgt_lang}/{speaker_id}: {e}")

async def just_send(ws: WebSocket, src_lang: str, text: str):

    try:
        await ws.send_json({
            "type" : "transcript_msg",
            "transcript": text,
            "src_lang": src_lang
        })
        print(f"WebSocket x recieved src_lang: {src_lang}")
    except Exception as e:
        print(f"Error: {e}")

async def per_record(connections, per: bool):
    for ws in connections:
        try:
            await ws.send_json({
                "type" : "per_record",
                "per_record": per,
            })
            print(f"per_record: {per}")
        except Exception as e:
            print(f"Error: {e}")

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    global current_recorder

    # Send current per_record state to the new user
    await websocket.send_json({
        "type": "per_record",
        "per_record": current_recorder is None  # True => Ø§Ø¬Ø§Ø²Ù‡ Ø±Ú©ÙˆØ±Ø¯ Ù‡Ø³Øª
    })

    # Set default values
    user_data = {
        "lang": "en-US",
        "speaker_id": "0",
        "last_ping": time.time()
    }

    # Add user to default room
    rooms[DEFAULT_ROOM][websocket] = user_data
    last_active = time.time()

    try:
        while True:
            try:
                data = await websocket.receive_json()
                last_active = time.time()
                # global current_recorder

                if data.get("type") == "update_settings":
                    lang = data.get("lang", "en-US")
                    speaker_id = int(data.get("speaker_id", "0"))
                    rooms[DEFAULT_ROOM][websocket]["lang"] = lang
                    rooms[DEFAULT_ROOM][websocket]["speaker_id"] = speaker_id
                    await websocket.send_json({"status": "settings_updated"})
                    print(f"WebSocket {websocket} updated settings: lang={lang}, speaker_id={speaker_id}")

                elif data.get("type") == "ping":
                    await websocket.send_json({"type": "pong"})
                    user_data["last_ping"] = last_active

                elif data.get("type") == "speak":
                    src_lang = data.get("src_lang")
                    text = data.get("text")
                    speaker_id = int(data.get("speaker_id", "0"))
                    print(f"ws x , src_lang: {src_lang} *type speak")
                    if not src_lang or not text:
                        continue

                    # Group users by their language + speaker_id
                    groups = defaultdict(list)
                    for ws, info in rooms[DEFAULT_ROOM].items():
                        key = (info["lang"], info["speaker_id"])
                        groups[key].append(ws)

                    tasks = []
                    for (tgt_lang, speaker_id), connections in groups.items():
                        if src_lang == tgt_lang:
                            for ws in connections:
                                tasks.append(
                                    just_send(ws, src_lang, text)
                                    )
                        else:
                            tasks.append(
                                group_translate(connections, src_lang, tgt_lang, text, speaker_id)
                            )
                    await asyncio.gather(*tasks)
                elif data.get("type") == "status_Record":
                    if data.get("statusRecord") == True:
                        await per_record(list(rooms[DEFAULT_ROOM].keys()), False)
                        current_recorder = websocket
                    elif data.get("statusRecord") == False:
                        await per_record(list(rooms[DEFAULT_ROOM].keys()), True)
                        current_recorder = None


            except Exception as e:
                print(f"Client error: {e}")
                break

            if time.time() - last_active > PING_TIMEOUT:
                print("Client inactive, disconnecting.")
                break

    except Exception as e:
        print(f"Connection error: {e}")

    finally:
        rooms[DEFAULT_ROOM].pop(websocket, None)

        # Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒÙ… Ú©Ù‡ Ø§Ú¯Ø± Ø§ÛŒÙ† Ú©Ø§Ø±Ø¨Ø± Ø±Ú©ÙˆØ±Ø¯Ø± Ø¨ÙˆØ¯ØŒ Ø¢Ù† Ø±Ø§ Ø®Ø§Ù„ÛŒ Ú©Ù†ÛŒÙ…
        if current_recorder == websocket:
            await per_record(list(rooms[DEFAULT_ROOM].keys()), True)
            current_recorder = None

        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø³ØªÙ† Ø³ÙˆÚ©Øª
        try:
            await websocket.close()
        except Exception as e:
            print(f"Error closing WebSocket: {e}")

    # finally:
    #     rooms[DEFAULT_ROOM].pop(websocket, None)
    #     if websocket.client_state != WebSocketState.DISCONNECTED:
    #         if current_recorder == websocket:
    #             await per_record(list(rooms[DEFAULT_ROOM].keys()), True)
    #             current_recorder = None
    #         try:
    #             await websocket.close()
    #         except Exception as e:
    #             print(f"Error closing WebSocket: {e}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run("your_module_name:app", host="0.0.0.0", port=8000, reload=True)
